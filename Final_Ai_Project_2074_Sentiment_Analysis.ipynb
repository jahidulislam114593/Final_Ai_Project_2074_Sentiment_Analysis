{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahidulislam114593/Final_Ai_Project_2074_Sentiment_Analysis/blob/main/Final_Ai_Project_2074_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb0ZeOmEVD0C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ek37WSCXVsL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEdTcwoCRomI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttN_UxfLVQcw"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shpT7D3ZYfT7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df['Clean'] = df.apply(lambda row: row['Text'].lower(),axis=1)\n",
        "\n",
        "df['Clean'] = df.apply(lambda row: re.sub(\"@[A-Za-z0-9_]+\",\"\", row['Clean']),axis=1)\n",
        "df['Clean'] = df.apply(lambda row: re.sub(\"#[A-Za-z0-9_]+\",\"\", row['Clean']),axis=1)\n",
        "\n",
        "df['Clean'] = df.apply(lambda row: re.sub(r\"www.\\S+\",\"\", row['Clean']),axis=1)\n",
        "df['Clean'] = df.apply(lambda row: re.sub(r\"http\\S+\",\"\", row['Clean']),axis=1)\n",
        "\n",
        "df['Clean'] = df.apply(lambda row: re.sub(\"[^a-z0-9]\",\" \", row['Clean']),axis=1)\n",
        "\n",
        "df = df[df['Language'] == 'en']\n",
        "\n",
        "df[['Text','Clean','Language','Label']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDQ3AAmpm4uP"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=0.40, random_state=42)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC7Em89QrdAP"
      },
      "source": [
        "# **Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzjTknuOo1Nu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and labels (y)\n",
        "X = df['Clean']\n",
        "y = df['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEjqsbxGhbBe"
      },
      "source": [
        "# **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2QJsJTJdzI"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer with desired settings\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=200, ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing data using the same vectorizer\n",
        "X_test = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY_FGlg1rijs"
      },
      "source": [
        "# **SVC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nq6JEvwLPVoR",
        "outputId": "074126fd-04c7-4ccd-9a1c-03dcd13b62e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   litigious       0.98      0.97      0.97     17918\n",
            "    negative       0.94      0.94      0.94     24592\n",
            "    positive       0.94      0.95      0.95     24744\n",
            " uncertainty       0.95      0.95      0.95     19877\n",
            "\n",
            "    accuracy                           0.95     87131\n",
            "   macro avg       0.95      0.95      0.95     87131\n",
            "weighted avg       0.95      0.95      0.95     87131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Create and train the Support Vector Classifier (SVC)\n",
        "svc_model = SVC(kernel='linear')  # You can choose different kernels and hyperparameters\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set and calculate accuracy\n",
        "y_pred = svc_model.predict(X_test)\n",
        "\n",
        "# Generate a classification report\n",
        "svc = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(svc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tbl6QNYrlbE"
      },
      "source": [
        "# **Multiclass Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TpbG9Ne9ZEOA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svc_model.predict(X_test)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Greys',\n",
        "            xticklabels=['negative', 'positive', 'uncertainty', 'litigious'],\n",
        "            yticklabels=['negative', 'positive', 'uncertainty', 'litigious'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Multiclass Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdCw_Gzr6C7"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NdgRGebJau1G"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create and train the Logistic Regression Classifier\n",
        "lr_model = LogisticRegression(max_iter=2000)  # You can adjust hyperparameters as needed\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set and calculate accuracy\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Generate a classification report for Logistic Regression\n",
        "lr = classification_report(y_test, y_pred_lr)\n",
        "\n",
        "# Print the classification report for Logistic Regression\n",
        "print(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wOM6ScTMdX13"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the confusion matrix using a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['negative', 'positive', 'uncertainty', 'litigious'],\n",
        "            yticklabels=['negative', 'positive', 'uncertainty', 'litigious'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Multiclass Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}